{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Part 4: Modern Feature Engineering - Distributed Representation for Text Modelling\n",
        "\n",
        "So far we have looked at traditional techniques that include using word frequency and weighting to determine the features from text and using those features to build classification models. On this note, we explore distributed representation as a way of generating features from words. In this notebook, we will look at the implementation of distributed representation techniques. More specifically\n",
        "\n",
        "#### Word2Vec Implementation with Gensim:\n",
        "1. Continuous Bag of Words Model\n",
        "2. Skip-Gram Model\n",
        "3. Gensim Vocabularity Object\n",
        "#### Word Vectors to Feature Matrix\n",
        "1. Averaging Word Vectors\n",
        "2. Building a vectorizer for new text"
      ],
      "metadata": {
        "id": "bKTPA0E2Zyry"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset: Restaurant Reviews\n",
        "Let's begin with importing the necessary package and read in the dataset"
      ],
      "metadata": {
        "id": "v59aadrAZ5_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "review_data = pd.read_csv('restaurant_reviews.tsv', sep='\\t')\n",
        "review_data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Ddk7LWoqZ5HT",
        "outputId": "97a80086-cd0b-4412-83f6-de01753f4ad3"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              Review  Liked\n",
              "0                           Wow... Loved this place.      1\n",
              "1                                 Crust is not good.      0\n",
              "2          Not tasty and the texture was just nasty.      0\n",
              "3  Stopped by during the late May bank holiday of...      1\n",
              "4  The selection on the menu was great and so wer...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65b851fc-7ec1-4c60-8248-14f477e1ba44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Liked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Wow... Loved this place.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Crust is not good.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Not tasty and the texture was just nasty.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Stopped by during the late May bank holiday of...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The selection on the menu was great and so wer...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65b851fc-7ec1-4c60-8248-14f477e1ba44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65b851fc-7ec1-4c60-8248-14f477e1ba44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65b851fc-7ec1-4c60-8248-14f477e1ba44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need to clean them up so that we have a sequence of words that we can build our word2vector representation. Before we go into the word2vec, let's use Keras to tokenize the sentiments."
      ],
      "metadata": {
        "id": "kp412ANZaCMh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import text_to_word_sequence\n",
        "    \n",
        "corpus_tokens = [text_to_word_sequence(review) for review in review_data.Review.values ]\n",
        "corpus_tokens[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rloWlvazaACy",
        "outputId": "91bffa84-f46e-48d1-f1a5-032105bcc62f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['wow', 'loved', 'this', 'place'],\n",
              " ['crust', 'is', 'not', 'good'],\n",
              " ['not', 'tasty', 'and', 'the', 'texture', 'was', 'just', 'nasty']]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that in the above example, we have created a list of documents in which every document is a set of tokens in the documents. This is the input we will need to use for our word2vec implementation."
      ],
      "metadata": {
        "id": "Zei9SHXLaOQJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Word2Vec?\n",
        "\n",
        "So far we have generally described distributed representation. The simplified understanding of distributed representation is the idea that words that have the same meaning tend to appear within the same context. More broadly, we distributed representation provides a way assign vectors to words based on the context such that words within a similar context are contained within the same vector space.\n",
        "\n",
        "For more information, see stanford's lecture: https://www.youtube.com/watch?v=ERibwqs9p38\n",
        "\n",
        "There are two main ways of computing word vectors:\n",
        "\n",
        "1. CBOW - Continuous Bag of Words\n",
        "2. Skip-Gram Model"
      ],
      "metadata": {
        "id": "NKN2I0pIaPEW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. CBOW - Continuous Bag of Words\n",
        "Suppose we have some text: \"generalized linear models have link functions that enable flexibility beyond that of ordinary least squares\". Also, suppose that we want to predict the word vector for the word \"models\", the continuous bag of words uses the context words: \"generalized linear ___ have link\" to predict the target word. Given the corpus may contain other texts with similar context, then we can train a cbow model to provide the most probable word for the text above.\n",
        "<br>\n",
        "\n",
        "If you are interested in understanding the mechanics of training word2vec, it may be useful to visit the Stanford link above for more technical details of the training algorithms available for this estimation.\n",
        "\n",
        "<br>\n",
        "In Python, I use the gensim package to compute the words vectors for the review corpus using cbow model\n",
        "\n",
        "<br>\n",
        "Before we implement cbow word2vec, we need to determine the following: \n",
        "\n",
        "<br>\n",
        "\n",
        "1. size of vector: The size of the vectors for every word in the corpus\n",
        "2. window size: The size of context words to use in computing the vector\n",
        "\n",
        "\n",
        "<br>\n",
        "In this example, let's use a window of 5 and a vector of size 10"
      ],
      "metadata": {
        "id": "TG11WOy6aZoY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "vector_size = 10\n",
        "window_size = 5\n",
        "\n",
        "cbow_model = Word2Vec(  sentences= corpus_tokens,\n",
        "                        vector_size = vector_size,  # Setting the vector size\n",
        "                        window =window_size,  # Setting the Window size\n",
        "                        sg=0,                                 # Initialize CBOW\n",
        "                        min_count = 2,               # Minimum word count\n",
        "                        sample=.0000001 )    # Lower Weighting/Downsampling of frequent words"
      ],
      "metadata": {
        "id": "21MRuvqHaErB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model has been trained. We can now extract a vector of size 10 using the 5 nearest words"
      ],
      "metadata": {
        "id": "pEFTw6vJbQR4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model.wv['good']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6VdcQpgbMOo",
        "outputId": "630d2f30-5ea1-4057-cd06-009a07b3386f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.07817571, -0.09510187, -0.00205531,  0.03469197, -0.00938972,\n",
              "        0.08381772,  0.09010784,  0.06536506, -0.00711621,  0.07710405],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. CBOW Similarity\n",
        "\n",
        "One of the advantages of using a CBOW model is we can then compute word similarity within the corpus. The cosine similarity method is used for this calculation.\n",
        "\n",
        "<br>\n",
        "Using the gensim package, we can call the most_similar method for any word as shown in the example below:"
      ],
      "metadata": {
        "id": "txyOwt3FbXIf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model.wv.most_similar('amazing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqYJVpaTbSN8",
        "outputId": "e7fb96b0-b352-4128-b51a-17edf8cd6841"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('mayo', 0.8547266721725464),\n",
              " ('pricing', 0.8052123785018921),\n",
              " ('twice', 0.802130401134491),\n",
              " ('40', 0.7712088227272034),\n",
              " ('so', 0.7700384855270386),\n",
              " ('party', 0.7527121305465698),\n",
              " ('liked', 0.735294759273529),\n",
              " ('say', 0.7321372628211975),\n",
              " ('terrible', 0.7217848896980286),\n",
              " ('part', 0.7145952582359314)]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Skip-Gram Model\n",
        "\n",
        "The Skip-Gram model is trained to perform the reverse function of the CBOW model. That is, while the cbow model predicts the target word given context words, the Skip-Gram model predicts context words based on the presence of the target word.\n",
        "\n",
        "<br>\n",
        "In terms of the general implementation of skip-gram in gensim, we will only activate the skip-gram argument. Let's see the implementation."
      ],
      "metadata": {
        "id": "RC4ablAJbhBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_model = Word2Vec(  sentences= corpus_tokens,\n",
        "                            vector_size = 20,    # Setting the vector size\n",
        "                            window = 5,          # Setting the Window size\n",
        "                            min_count = 2,       # Minimum word count\n",
        "                            sg = 1,              # Initialize Skip Gram\n",
        "                            sample=.0000001 )    # Lower Weighting/Downsampling of frequent words"
      ],
      "metadata": {
        "id": "qVS_Fea2bc8I"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just like with CBOW, we can generate a word vector for each word in the corpus"
      ],
      "metadata": {
        "id": "FYyox2hRbqGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_model.wv['good']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8RNYKoubnkr",
        "outputId": "bd10ae41-2389-4282-c169-ecad6cefc2a5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.04121573,  0.04649187, -0.00098335, -0.00983143,  0.02302161,\n",
              "       -0.02047365,  0.01371725,  0.03470667,  0.03032966, -0.03756103,\n",
              "        0.04690514,  0.0233656 ,  0.01983496, -0.03122055,  0.0423056 ,\n",
              "       -0.01075502,  0.04413366, -0.02680901, -0.04064848,  0.03411919],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Skip-Gram Word Similarity\n",
        "\n",
        "We can also retrieve similar words from the skip-gram model."
      ],
      "metadata": {
        "id": "AVhZay-3buQQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_model.wv.similar_by_word('amazing')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D97diK1HbsCU",
        "outputId": "0b3dd733-b572-4077-86b7-bdb4720dc391"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('wait', 0.6336723566055298),\n",
              " ('gone', 0.6114690899848938),\n",
              " ('bartender', 0.6109290719032288),\n",
              " ('money', 0.5625681281089783),\n",
              " ('omg', 0.5368884205818176),\n",
              " ('promise', 0.5267219543457031),\n",
              " ('stayed', 0.5241491198539734),\n",
              " ('seems', 0.522510290145874),\n",
              " ('who', 0.5187430381774902),\n",
              " ('thumbs', 0.5136153697967529)]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Gensim Vocabulary\n",
        "\n",
        "Suppose we have a new text input that may have new words that our models have not seen yet, it is therefore impossible to return the vectors for those words. It is always important to know how to access the vocabulary in the model so that you can provide an alternative to new words are you are trying to leverage the models for feature extraction.\n",
        "\n",
        "<br>\n",
        "The gensim vocabulary is a dictionary of all words with the vector object."
      ],
      "metadata": {
        "id": "WDVSxYeEbzgH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = skipgram_model.wv.index_to_key\n",
        "vocab[20:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C30sratpbxJK",
        "outputId": "7d9e73e6-4a73-4d97-9555-cf1c422a060c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['with', 'had', 'great', 'that', 'be', 'so', 'were', 'are', 'but', 'have']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(vocab)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PIRhIwub3El",
        "outputId": "b2c997b6-1b43-4318-9445-9b995ef6662e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "897"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Convert Word Vectors to Features\n",
        "\n",
        "We have seen earlier how to implement bag of words and tfidf feature extraction. With those techniques, every word has a single value as a feature. With word vectors, every word has a vector of features so we will need to find a way to summarize the features such that every document has one vector representing all the tokens in the document. One simple approach is to sum the vectors and average them by the count of the words/tokens.\n",
        "\n",
        "<br>\n",
        "Let's see this in implementation"
      ],
      "metadata": {
        "id": "ODjw_Xjeb6QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def avg_word_vectors(words, model, vocabulary, feature_size):\n",
        "    \n",
        "    feature_vector = np.zeros((feature_size,), dtype='float64')\n",
        "    word_count = 0.\n",
        "    \n",
        "    for word in words:\n",
        "        if word in vocabulary:\n",
        "            word_count += 1\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "            \n",
        "        if word_count:\n",
        "            feature_vector = np.divide(feature_vector, word_count)\n",
        "            \n",
        "    return feature_vector\n"
      ],
      "metadata": {
        "id": "y6I9o-Qmb4lv"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the function on a sample of text"
      ],
      "metadata": {
        "id": "tysf8HQncBjf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = [\"This\", 'is', 'delicious', 'food']\n",
        "avg_word_vectors(test, skipgram_model, vocab, 20 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVOqoGPYb-Fd",
        "outputId": "2975b91f-09ad-4ae7-de28-9957991dc4f4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.00381702, -0.00316857,  0.00247694, -0.00598015,  0.02107186,\n",
              "        0.0180915 , -0.00301856,  0.01412969, -0.01600609,  0.01004132,\n",
              "        0.0075589 , -0.00288089,  0.01646154, -0.00441363,  0.01078511,\n",
              "       -0.01157882,  0.02155005,  0.01900969, -0.01142925,  0.00739343])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Averaging across the full dataset\n",
        "\n",
        "Now let's convert the averaged vectors to a full dataframe with words as the predictors/features"
      ],
      "metadata": {
        "id": "Y5d9b1ofcFqi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def avg_word_vectorizer(corpus, model, feature_size):\n",
        "    vocabulary = set(model.wv.index_to_key)\n",
        "    features = [ avg_word_vectors(text, model, vocabulary, feature_size) for text in corpus]\n",
        "    \n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "skipgram_feaures = avg_word_vectorizer(corpus_tokens, skipgram_model, 20)"
      ],
      "metadata": {
        "id": "GqSIrZXAcDVS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Converting Vectors into a Feature Dataframe"
      ],
      "metadata": {
        "id": "s-DQ4gmHcKOz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skipgram_df = pd.DataFrame(skipgram_feaures)\n",
        "skipgram_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "Pc8XXVWScIeh",
        "outputId": "ef02812b-f235-488e-c646-79b440cde6b6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6   \\\n",
              "0  0.002200 -0.015287 -0.015425 -0.001512  0.001022 -0.004541 -0.002240   \n",
              "1 -0.014202  0.009345 -0.001474 -0.007928  0.008754 -0.004882  0.004632   \n",
              "2  0.000496 -0.003071  0.000526  0.000306  0.003619 -0.001678  0.001542   \n",
              "3 -0.004266  0.001542 -0.002245 -0.002431  0.001924  0.002580  0.003604   \n",
              "4 -0.001113  0.000919 -0.000484  0.003836  0.003093  0.000356  0.001461   \n",
              "\n",
              "         7         8         9         10        11        12        13  \\\n",
              "0 -0.010102  0.013118  0.002800 -0.002498  0.004954  0.007783 -0.005989   \n",
              "1  0.012017  0.003751 -0.007202  0.017074  0.002244  0.002607 -0.011181   \n",
              "2 -0.001002  0.002840  0.003904 -0.002766 -0.005903 -0.002449  0.004655   \n",
              "3 -0.002653  0.003792  0.003001 -0.001501 -0.003569  0.002076  0.002506   \n",
              "4  0.002986  0.000749  0.002564  0.000360 -0.001045  0.002020 -0.001210   \n",
              "\n",
              "         14        15        16        17        18        19  \n",
              "0  0.013167  0.012485  0.009511  0.004616  0.010194 -0.006662  \n",
              "1  0.006813 -0.003037  0.014002 -0.004456 -0.007994  0.012142  \n",
              "2 -0.004210 -0.004335  0.003840 -0.005615 -0.003023 -0.004575  \n",
              "3  0.000086 -0.002937 -0.003272 -0.000946  0.002147 -0.001985  \n",
              "4 -0.001275  0.003626 -0.003685 -0.001368 -0.001514  0.001991  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-964f3b8d-2214-434c-ad07-5b06049cd41f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.002200</td>\n",
              "      <td>-0.015287</td>\n",
              "      <td>-0.015425</td>\n",
              "      <td>-0.001512</td>\n",
              "      <td>0.001022</td>\n",
              "      <td>-0.004541</td>\n",
              "      <td>-0.002240</td>\n",
              "      <td>-0.010102</td>\n",
              "      <td>0.013118</td>\n",
              "      <td>0.002800</td>\n",
              "      <td>-0.002498</td>\n",
              "      <td>0.004954</td>\n",
              "      <td>0.007783</td>\n",
              "      <td>-0.005989</td>\n",
              "      <td>0.013167</td>\n",
              "      <td>0.012485</td>\n",
              "      <td>0.009511</td>\n",
              "      <td>0.004616</td>\n",
              "      <td>0.010194</td>\n",
              "      <td>-0.006662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.014202</td>\n",
              "      <td>0.009345</td>\n",
              "      <td>-0.001474</td>\n",
              "      <td>-0.007928</td>\n",
              "      <td>0.008754</td>\n",
              "      <td>-0.004882</td>\n",
              "      <td>0.004632</td>\n",
              "      <td>0.012017</td>\n",
              "      <td>0.003751</td>\n",
              "      <td>-0.007202</td>\n",
              "      <td>0.017074</td>\n",
              "      <td>0.002244</td>\n",
              "      <td>0.002607</td>\n",
              "      <td>-0.011181</td>\n",
              "      <td>0.006813</td>\n",
              "      <td>-0.003037</td>\n",
              "      <td>0.014002</td>\n",
              "      <td>-0.004456</td>\n",
              "      <td>-0.007994</td>\n",
              "      <td>0.012142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000496</td>\n",
              "      <td>-0.003071</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.000306</td>\n",
              "      <td>0.003619</td>\n",
              "      <td>-0.001678</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>-0.001002</td>\n",
              "      <td>0.002840</td>\n",
              "      <td>0.003904</td>\n",
              "      <td>-0.002766</td>\n",
              "      <td>-0.005903</td>\n",
              "      <td>-0.002449</td>\n",
              "      <td>0.004655</td>\n",
              "      <td>-0.004210</td>\n",
              "      <td>-0.004335</td>\n",
              "      <td>0.003840</td>\n",
              "      <td>-0.005615</td>\n",
              "      <td>-0.003023</td>\n",
              "      <td>-0.004575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.004266</td>\n",
              "      <td>0.001542</td>\n",
              "      <td>-0.002245</td>\n",
              "      <td>-0.002431</td>\n",
              "      <td>0.001924</td>\n",
              "      <td>0.002580</td>\n",
              "      <td>0.003604</td>\n",
              "      <td>-0.002653</td>\n",
              "      <td>0.003792</td>\n",
              "      <td>0.003001</td>\n",
              "      <td>-0.001501</td>\n",
              "      <td>-0.003569</td>\n",
              "      <td>0.002076</td>\n",
              "      <td>0.002506</td>\n",
              "      <td>0.000086</td>\n",
              "      <td>-0.002937</td>\n",
              "      <td>-0.003272</td>\n",
              "      <td>-0.000946</td>\n",
              "      <td>0.002147</td>\n",
              "      <td>-0.001985</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.001113</td>\n",
              "      <td>0.000919</td>\n",
              "      <td>-0.000484</td>\n",
              "      <td>0.003836</td>\n",
              "      <td>0.003093</td>\n",
              "      <td>0.000356</td>\n",
              "      <td>0.001461</td>\n",
              "      <td>0.002986</td>\n",
              "      <td>0.000749</td>\n",
              "      <td>0.002564</td>\n",
              "      <td>0.000360</td>\n",
              "      <td>-0.001045</td>\n",
              "      <td>0.002020</td>\n",
              "      <td>-0.001210</td>\n",
              "      <td>-0.001275</td>\n",
              "      <td>0.003626</td>\n",
              "      <td>-0.003685</td>\n",
              "      <td>-0.001368</td>\n",
              "      <td>-0.001514</td>\n",
              "      <td>0.001991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-964f3b8d-2214-434c-ad07-5b06049cd41f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-964f3b8d-2214-434c-ad07-5b06049cd41f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-964f3b8d-2214-434c-ad07-5b06049cd41f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Conclusion\n",
        "\n",
        "What we have done is reduce all of our text to a dataframe that has 20 features representing the average of all of the word vectors for the word in the text. We can use this matrix for some of the classification tasks that we did before. In the last section, we will cover how to use deep learning for the classification of the sentiments."
      ],
      "metadata": {
        "id": "PAFZjfFbcO6k"
      }
    }
  ]
}